{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magics, Imports, and Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pyedflib\n",
    "import re\n",
    "from subprocess import call\n",
    "import sys\n",
    "import typing\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.7.1 (default, Dec 14 2018, 19:28:38) \n",
      "[GCC 7.3.0]\n",
      "__pyTorch VERSION: 1.0.1.post2\n",
      "__fastai VERSION: 1.0.53.dev0\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n",
      "__CUDNN VERSION: 7402\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices: 1\n",
      "Current cuda device 0\n"
     ]
    }
   ],
   "source": [
    "print(f'__Python VERSION: {sys.version}')\n",
    "\n",
    "try:\n",
    "    print(f'__pyTorch VERSION: {torch.__version__}')\n",
    "    PYTORCH = True\n",
    "except: \n",
    "    print(\"Pytorch Not Installed\")\n",
    "    PYTORCH = False\n",
    "\n",
    "try:\n",
    "    print(f'__fastai VERSION: {fastai.__version__}')\n",
    "except:\n",
    "    print(\"fastai Not Installed\")\n",
    "    \n",
    "print('__CUDA VERSION')\n",
    "\n",
    "! nvcc --version\n",
    "\n",
    "if PYTORCH:\n",
    "    print(f'__CUDNN VERSION: {torch.backends.cudnn.version()}')\n",
    "    print(f'__Number CUDA Devices: {torch.cuda.device_count()}')\n",
    "    \n",
    "print(f'__Devices')\n",
    "\n",
    "try:\n",
    "    call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "    print(f'Active CUDA Device: GPU {torch.cuda.current_device()}')\n",
    "\n",
    "    print (f'Available devices: {torch.cuda.device_count()}')\n",
    "    print (f'Current cuda device {torch.cuda.current_device()}')\n",
    "except:\n",
    "    print(\"No GPUs Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = Path(f'{os.getcwd()}')\n",
    "data_path = here.parent/'data'\n",
    "raw_path = data_path/'raw'/'v1.5.0/edf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build List of Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_files = []\n",
    "for (dir_path, dir_names, file_names) in os.walk(raw_path):\n",
    "    max_eeg = [re.search('t(\\d*)',file.split('/')[-1])[1] for file in file_names]\n",
    "    m = max(max_eeg) if len(max_eeg) >= 1 else 0\n",
    "    for file in file_names:\n",
    "        if file.endswith('.edf'):\n",
    "            working_files.append((dir_path + '/' + file, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t002.edf',\n",
       "  '003'),\n",
       " ('/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t001.edf',\n",
       "  '003'),\n",
       " ('/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t003.edf',\n",
       "  '003'),\n",
       " ('/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s001_2007_09_25/00004151_s001_t001.edf',\n",
       "  '001'),\n",
       " ('/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/032/00003281/s001_2006_10_09/00003281_s001_t001.edf',\n",
       "  '001')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({14: 5610})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure that they all have the same structure\n",
    "nums = []\n",
    "for file, m in working_files:\n",
    "    nums.append(len(file.split('/')))\n",
    "collections.Counter(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = collections.defaultdict(list)\n",
    "for file, m in working_files:\n",
    "    split = file.split('/')\n",
    "    data_type = split[8]\n",
    "    config = split[9].split('_')[-1]\n",
    "    patient_id = split[11]\n",
    "    long = split[12].split('_')\n",
    "    session = long[0].strip('s')\n",
    "    date = f'{long[1]}/{long[2]}/{long[3].strip(patient_id)}' \n",
    "    segment = re.search('t(\\d*)',split[13])[1]\n",
    "    f = pyedflib.EdfReader(file)\n",
    "    channels = str(f.signals_in_file)\n",
    "    num_obs = str(f.getNSamples()[0])\n",
    "    label_file = file[:-3]+'tse'\n",
    "    with open(label_file,'r') as f:\n",
    "        labels, durations = [], []\n",
    "        for line in f.readlines()[2:]:\n",
    "            labels.append(line.split(' ')[2])\n",
    "            durations.append(line.split(' ')[1])\n",
    "    sample_rate = str(float(num_obs) / float(durations[-1]))\n",
    "    d[patient_id].append({'date':date, \n",
    "                          'session':session, \n",
    "                          'segment':segment, \n",
    "                          'total_segments':m, \n",
    "                          'labels':labels,\n",
    "                          'durations': durations,\n",
    "                          'channels':channels,\n",
    "                          'number_obs': num_obs,\n",
    "                          'sample_rate': sample_rate,\n",
    "                          'config':config, \n",
    "                          'type':data_type, \n",
    "                          'loc':file,\n",
    "                          'label_file': label_file\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2007/09/28',\n",
       "  'session': '002',\n",
       "  'segment': '002',\n",
       "  'total_segments': '003',\n",
       "  'labels': ['bckg'],\n",
       "  'durations': ['256.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '64000',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t002.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t002.tse'},\n",
       " {'date': '2007/09/28',\n",
       "  'session': '002',\n",
       "  'segment': '001',\n",
       "  'total_segments': '003',\n",
       "  'labels': ['bckg'],\n",
       "  'durations': ['490.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '122500',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t001.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t001.tse'},\n",
       " {'date': '2007/09/28',\n",
       "  'session': '002',\n",
       "  'segment': '003',\n",
       "  'total_segments': '003',\n",
       "  'labels': ['bckg'],\n",
       "  'durations': ['443.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '110750',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t003.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t003.tse'},\n",
       " {'date': '2007/09/2',\n",
       "  'session': '001',\n",
       "  'segment': '001',\n",
       "  'total_segments': '001',\n",
       "  'labels': ['bckg', 'fnsz', 'bckg', 'fnsz', 'bckg', 'fnsz', 'bckg'],\n",
       "  'durations': ['57.2880',\n",
       "   '162.7440',\n",
       "   '711.1520',\n",
       "   '836.1520',\n",
       "   '1070.8880',\n",
       "   '1157.0200',\n",
       "   '1423.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '355750',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s001_2007_09_25/00004151_s001_t001.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s001_2007_09_25/00004151_s001_t001.tse'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['00004151']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary to json\n",
    "with open(here.parent/'data_dict.json', 'w') as file:\n",
    "     file.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file back in \n",
    "with open(here.parent/'data_dict.json', 'r') as file:\n",
    "     data_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure they are the same\n",
    "data_dict['00004151'] == d['00004151']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
