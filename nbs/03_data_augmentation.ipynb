{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magics, Imports, and Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import operator\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pyedflib\n",
    "from scipy import signal\n",
    "from subprocess import call\n",
    "import sys\n",
    "import typing\n",
    "import urllib\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.7.1 (default, Dec 14 2018, 19:28:38) \n",
      "[GCC 7.3.0]\n",
      "__pyTorch VERSION: 1.0.1.post2\n",
      "__fastai VERSION: 1.0.53.dev0\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n",
      "__CUDNN VERSION: 7402\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices: 1\n",
      "Current cuda device 0\n"
     ]
    }
   ],
   "source": [
    "print(f'__Python VERSION: {sys.version}')\n",
    "\n",
    "try:\n",
    "    print(f'__pyTorch VERSION: {torch.__version__}')\n",
    "    PYTORCH = True\n",
    "except: \n",
    "    print(\"Pytorch Not Installed\")\n",
    "    PYTORCH = False\n",
    "\n",
    "try:\n",
    "    print(f'__fastai VERSION: {fastai.__version__}')\n",
    "except:\n",
    "    print(\"fastai Not Installed\")\n",
    "    \n",
    "print('__CUDA VERSION')\n",
    "\n",
    "! nvcc --version\n",
    "\n",
    "if PYTORCH:\n",
    "    print(f'__CUDNN VERSION: {torch.backends.cudnn.version()}')\n",
    "    print(f'__Number CUDA Devices: {torch.cuda.device_count()}')\n",
    "    \n",
    "print(f'__Devices')\n",
    "\n",
    "try:\n",
    "    call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "    print(f'Active CUDA Device: GPU {torch.cuda.current_device()}')\n",
    "\n",
    "    print (f'Available devices: {torch.cuda.device_count()}')\n",
    "    print (f'Current cuda device {torch.cuda.current_device()}')\n",
    "except:\n",
    "    print(\"No GPUs Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load In Data Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = Path(f'{os.getcwd()}')\n",
    "data_path = here.parent/'data'\n",
    "raw_path = data_path/'raw'/'v1.5.0/edf'\n",
    "with open(here/'data_dict.json', 'r') as file:\n",
    "     data_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2007/09/28',\n",
       "  'session': '002',\n",
       "  'segment': '002',\n",
       "  'total_segments': '003',\n",
       "  'labels': ['bckg'],\n",
       "  'durations': ['256.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '64000',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t002.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t002.tse'},\n",
       " {'date': '2007/09/28',\n",
       "  'session': '002',\n",
       "  'segment': '001',\n",
       "  'total_segments': '003',\n",
       "  'labels': ['bckg'],\n",
       "  'durations': ['490.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '122500',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t001.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t001.tse'},\n",
       " {'date': '2007/09/28',\n",
       "  'session': '002',\n",
       "  'segment': '003',\n",
       "  'total_segments': '003',\n",
       "  'labels': ['bckg'],\n",
       "  'durations': ['443.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '110750',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t003.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s002_2007_09_28/00004151_s002_t003.tse'},\n",
       " {'date': '2007/09/2',\n",
       "  'session': '001',\n",
       "  'segment': '001',\n",
       "  'total_segments': '001',\n",
       "  'labels': ['bckg', 'fnsz', 'bckg', 'fnsz', 'bckg', 'fnsz', 'bckg'],\n",
       "  'durations': ['57.2880',\n",
       "   '162.7440',\n",
       "   '711.1520',\n",
       "   '836.1520',\n",
       "   '1070.8880',\n",
       "   '1157.0200',\n",
       "   '1423.0000'],\n",
       "  'channels': '41',\n",
       "  'number_obs': '355750',\n",
       "  'sample_rate': '250.0',\n",
       "  'config': 'le',\n",
       "  'type': 'dev_test',\n",
       "  'loc': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s001_2007_09_25/00004151_s001_t001.edf',\n",
       "  'label_file': '/home/jupyter/tuh_eeg/data/raw/v1.5.0/edf/dev_test/02_tcp_le/041/00004151/s001_2007_09_25/00004151_s001_t001.tse'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['00004151']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f'Creating {directory}')\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir(data_path/'augmented')\n",
    "ensure_dir(data_path/'augmented/train_val')\n",
    "ensure_dir(data_path/'augmented/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = data_path/'augmented/train_val'\n",
    "test_path = data_path/'augmented/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design New File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\"{config}_{key}_s{session}_d{date}_t{segment}_ts{total_segments}_ch{ch}_h{h}_w{w}_o{o}_st{st}_et{et}_p{p}_tp{tp}\"\n",
    "# le_00004151_s002_d2007_09_28_t002_ts003_ch041_h12_w1_o25_st00005.25_et00006.25_p00008_tp00342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Transformations and Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_eeg(eeg, key, entry, h=0, w=0, op=0):\n",
    "    length = float(entry['durations'][-1])\n",
    "    step_value = w - (w * (op/100))\n",
    "    piece = 1\n",
    "    total_pieces = len(np.arange(0,length,step_value))\n",
    "    for start in np.arange(0, length, step_value):\n",
    "        end = start + w\n",
    "        fn = build_filename(key, entry, h, w, op, start, end, piece, total_pieces)\n",
    "        start_obs = int(start * h)\n",
    "        end_obs = int(end * h)\n",
    "        new_eeg = eeg[::,start_obs:end_obs]\n",
    "        #save_eeg(new_eeg, fn, value)\n",
    "        write_labels(start, end, entry, fn)\n",
    "        piece += 1\n",
    "        \n",
    "\n",
    "def write_labels(start, end, entry, fn):\n",
    "    ground_truth = zip(entry['durations'],entry['labels'])\n",
    "    \n",
    "    \n",
    "def down_sample_eeg(eeg, entry, h):\n",
    "    num_elems = int(float(entry['durations'][-1])) * h\n",
    "    dn_sampled = signal.resample(eeg, num=num_elems, axis=1)\n",
    "    return dn_sampled\n",
    "\n",
    "\n",
    "def save_eeg(new_eeg, fn, value):\n",
    "    if value['type'] == 'dev_test':\n",
    "        np.save(f'{test_path/fn}.npy',new_eeg)\n",
    "    else:\n",
    "        np.save(f'{train_path/fn}.npy',new_eeg)\n",
    "\n",
    "        \n",
    "def get_eeg(entry):\n",
    "    f = pyedflib.EdfReader(entry['loc'])\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[i, :] = f.readSignal(i)\n",
    "    return sigbufs\n",
    "    \n",
    "    \n",
    "def build_filename(key, entry, h, w ,op, st, et, p, tp):\n",
    "    date = entry['date'].replace('/','_')\n",
    "    s = entry['session']\n",
    "    c = entry['config']\n",
    "    t = entry['segment']\n",
    "    ts = entry['total_segments']\n",
    "    ch = entry['channels']\n",
    "    return f\"{c}_{key}_s{s}_d{date}_t{t}_ts{ts}_ch{ch.zfill(3)}_h{h}_w{w}_o{o}_st{str(st).zfill(8)}_et{str(et).zfill(8)}_p{str(p).zfill(5)}_tp{str(tp).zfill(5)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 64000)\n",
      "12 (41, 3072)\n",
      "24 (41, 6144)\n",
      "48 (41, 12288)\n",
      "64 (41, 16384)\n",
      "96 (41, 24576)\n",
      "(41, 122500)\n",
      "12 (41, 5880)\n",
      "24 (41, 11760)\n",
      "48 (41, 23520)\n",
      "64 (41, 31360)\n",
      "96 (41, 47040)\n",
      "(41, 110750)\n",
      "12 (41, 5316)\n",
      "24 (41, 10632)\n",
      "48 (41, 21264)\n",
      "64 (41, 28352)\n",
      "96 (41, 42528)\n",
      "(41, 355750)\n",
      "12 (41, 17076)\n",
      "24 (41, 34152)\n",
      "48 (41, 68304)\n",
      "64 (41, 91072)\n",
      "96 (41, 136608)\n"
     ]
    }
   ],
   "source": [
    "H_VALUES, W_VALUES, O_VALUES = (12,24,48,64,96), (1,2,4,6,8), (25,50,75)\n",
    "for key, value in data_dict.items():\n",
    "    if key == '00004151':\n",
    "        for entry in value:\n",
    "            eeg = get_eeg(entry)\n",
    "            print(eeg.shape)\n",
    "            for h in H_VALUES:\n",
    "                dn_sampled = down_sample_eeg(eeg, entry, h)\n",
    "                print(h, dn_sampled.shape)\n",
    "                for w ,o in list(itertools.product(W_VALUES, O_VALUES)):\n",
    "                    process_eeg(dn_sampled, key, entry, h, w, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDF Contents (preserve?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_close', '_convert_string', '_get_float', 'admincode', 'annotations_in_file', 'birthdate', 'check_open_ok', 'datarecord_duration', 'datarecords_in_file', 'digital_max', 'digital_min', 'equipment', 'file_duration', 'file_info', 'file_info_long', 'file_name', 'gender', 'getAdmincode', 'getBirthdate', 'getDigitalMaximum', 'getDigitalMinimum', 'getEquipment', 'getFileDuration', 'getGender', 'getHeader', 'getLabel', 'getNSamples', 'getPatientAdditional', 'getPatientCode', 'getPatientName', 'getPhysicalDimension', 'getPhysicalMaximum', 'getPhysicalMinimum', 'getPrefilter', 'getRecordingAdditional', 'getSampleFrequencies', 'getSampleFrequency', 'getSignalHeader', 'getSignalHeaders', 'getSignalLabels', 'getStartdatetime', 'getTechnician', 'getTransducer', 'handle', 'load_datarecord', 'make_buffer', 'open', 'patient', 'patient_additional', 'patientcode', 'patientname', 'physical_dimension', 'physical_max', 'physical_min', 'prefilter', 'readAnnotations', 'readSignal', 'read_annotation', 'read_digital_signal', 'readsignal', 'recording_additional', 'samplefrequency', 'samples_in_datarecord', 'samples_in_file', 'signal_label', 'signals_in_file', 'startdate_day', 'startdate_month', 'startdate_year', 'starttime_hour', 'starttime_minute', 'starttime_second', 'technician', 'transducer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
